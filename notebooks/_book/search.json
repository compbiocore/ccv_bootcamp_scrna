[
  {
    "objectID": "index.html#to-use-this-notebook",
    "href": "index.html#to-use-this-notebook",
    "title": "Introduction",
    "section": "0.1 To use this notebook",
    "text": "0.1 To use this notebook\n\nGo to ood.ccv.brown.edu (you will need an Oscar account).\nGo to ‘Clusters’ in the blue menu bar at the top and click the drop-down that says ‘&gt;_OSCAR Shell Access’\nGo to your home folder and make a folder called scrna_r_workshop_2023 (cd ~ and mkdir scrna_r_workshop_2023), then type pwd to get the path to this folder.\nLook under Interactive Apps in the blue menu bar and click on RStudio on Singularity under Expert GUIs.\n\nFill in the fields as follows:\n\nAccount: leave blank\n\nPartition: leave blank\n\nNumber of hours: 3\n\nNum Cores: 8\n\nMemory: 90\n\nSingularity Container Path:/gpfs/data/shared/databases/workshops/bootcamp_2023/scrna_r_workshop.sif\n\nPackage install Path: leave blank\n\nPath for R Executable: This should be the full path to the scrna_r_workshop_2023 you made in step 3.\n\nR Module: leave blank\n\nAdditional Data Path: /gpfs/data/shared/databases/workshops/bootcamp_2023/scrna_r_workshop\n\n\nOnce your job starts, click the button to connect to session.\nAt the top of the screen you’ll see a menu bar that starts with ‘file’, click on ‘file’ and ‘open file’.\nIt will ask for a File name – paste this into the box: /gpfs/data/shared/databases/workshops/bootcamp_2023/scrna_r_workshop/intro.Rmd"
  },
  {
    "objectID": "index.html#introduction-to-scrna-seq",
    "href": "index.html#introduction-to-scrna-seq",
    "title": "Introduction",
    "section": "0.2 Introduction to scRNA-seq",
    "text": "0.2 Introduction to scRNA-seq\nWhat we will cover\n- How does scRNA-seq differ from bulk RNA-seq?\n- scRNAseq technologies\n- Parallelization options for Seurat and other packages\n- Seurat objects and importing data\n- Data merging, QC, and filtering\n- SCTransform normalization, clustering, dimension reduction\n- Data integration  - Differential expression testing\n- Data visualization\n- Classifying cell types with a reference atlas with TransferAnchors from Seurat\n\nMuch of this notebook is adapted from the Seurat vignettes https://satijalab.org/seurat and GitHub repository https://github.com/satijalab/seurat"
  },
  {
    "objectID": "index.html#how-does-scrna-seq-differ-from-bulk-rna-seq",
    "href": "index.html#how-does-scrna-seq-differ-from-bulk-rna-seq",
    "title": "Introduction",
    "section": "0.3 How does scRNA-seq differ from bulk RNA-seq?",
    "text": "0.3 How does scRNA-seq differ from bulk RNA-seq?\n\n\n\nbulk vs single cell\n\n\n\nIn bulk RNA-seq you are taking a snapshot of expression of all the cells in a sample and your measurements are aggregated across all of those cells.\nIn scRNA-seq, you can get a sense of the heterogeneity of the cells in your sample.\n\nAre there novel or rare cell types?\nWhat about cell type specific gene expression?\nDoes the distribution of different cell types change across time or treatment?\n\nThis increased resolution comes with some unique challenges.\n\nDropouts - genes that are not detected in some cells, can lead to sparse expression matrices with many zero values.\nDoublets - sequencing two cells at the same time and can’t distinguish their expression or cell types, need to filter these out during QC.\nDying cells - you will lose some cells because they are dead or dying, you can also filter these out during sample QC.\nYou also should be cautious when thinking about your sample sizes. For example, you may be sequencing thousands of cells but if they all come from the same mouse you lose the ability to generalize your findings."
  },
  {
    "objectID": "index.html#scrnaseq-technologies",
    "href": "index.html#scrnaseq-technologies",
    "title": "Introduction",
    "section": "0.4 scRNAseq technologies",
    "text": "0.4 scRNAseq technologies\n\nAlthough 10X genomics is probably the most popular technology for scRNA-seq, there are other flavors as well (see PMID 30472192 and PMID 28212749).\n\n\n10x sequencing encapsulates a cell, reagents, and a bead w/ primer in an oil droplet (aka GEM or Gel Bead-in EMulsion). Again, if you have a situation where one droplet has two cells, this is a ‘doublet’, you can also have empty droplets where there’s no cell encapsulated.\n\nAfter encapsulation of cells, beads, and reagents in the oil droplets, the bead is dissolved and releases primers. The poly (dT) primers are used for generating the gene expression libraries. The capture sequence primers are shown in a lighter shading because they are only used in situations where you’d like to add an extra channel of information to your experiment by using feature barcoding (cell-surface protein characterization, multiplexing, etc.)."
  },
  {
    "objectID": "index.html#library-preparation-details",
    "href": "index.html#library-preparation-details",
    "title": "Introduction",
    "section": "0.5 Library preparation details",
    "text": "0.5 Library preparation details\nLet’s go over the details of how the library prep works (see https://teichlab.github.io/scg_lib_structs/methods_html/10xChromium3.html)\nThe polyA mRNAs are captured using the oligo(dT) on the beads, MMLV (Moloney Murine Leukemia Virus) reverse transcriptase synthesizes complementary strand to the fragment thats captured.\\\\\n\nThe RT adds some extra Cs on the end.\\\\\n\nThe template-switching oligo is added so we can continue across the other strand.\\\\\n Add primers to amplify full length cDNA\\\\\n Fragment cDNA, perform A-tailing\\\\\n At this point we add the Truseq adapters, product 3 is what you’ll actually sequence.\\\\\n\nAdd the library PCR primers 1 and 2 to amplify the library\\\\\nThe final library structure looks like the above image – the exact length of the UMI might depend on which chemistry you’re using.\nThe actual sequencing looks like the above image. Truseq Read 1 uses bottom strand as template and sequences the bacrode + UMI. Sample Index primer sequences the sample index using bottom strand as template. Regenerate clusters and Truseq Read 2 primer sequences the second read using the top strand as template.\\\\\n\nThe above steps assume a single index library, if you’re using dual indexes there will be another sample index between the P5 and Truseq Read 1. Dual indexed libraries are beneficial to help prevent index hopping (https://www.10xgenomics.com/blog/sequence-with-confidence-understand-index-hopping-and-how-to-resolve-it).\\\\\n::: {.callout-tip}\n## Tip \nhttps://teichlab.github.io/scg_lib_structs/ is an excellent resource for information about the resulting library structures for 10x libraries (and other single cell technologies like Drop-seq or SMART-seq) and was our resource for most of this section.\n:::"
  },
  {
    "objectID": "index.html#parallelization-options-for-seurat-and-other-packages",
    "href": "index.html#parallelization-options-for-seurat-and-other-packages",
    "title": "Introduction",
    "section": "0.6 Parallelization options for Seurat and other packages",
    "text": "0.6 Parallelization options for Seurat and other packages\nLet’s get started. First, we can set the .libPaths(), which essentially tells R that it should look for packages inside these locations inside the Singularity container.\nAll of the methods we are discussing here involve computationally heavy methods, and as such also take advantage of parallelization where they can. Often in their documentation you will find how to use multiple cores when calling a function, usually involving a provided argument or involving a package called future.\nFor example, Seurat has a vignette on parallelization with future. We will follow it here:\n\nlibrary(future)\n# check the current active plan\nplan()\n\nsequential:\n- args: function (..., envir = parent.frame())\n- tweaked: FALSE\n- call: NULL\n\n\nplan() says that we are currently set up to run code sequentially or non-parallelized. To see more information, run this code chunk:\n\n?future::plan\n\nNow, we set workers=8 because we’ve requested 8 cores. Additionally, we set multisession instead of multiprocess despite what the vignette says, because multiprocess is actually deprecated in future and we should be explicitly specifying multisession or multicore instead. Getting into the difference is out of scope of this workshop, but you can read more on future yourself if interested.\n\n# change the current plan to access parallelization\nplan(\"multisession\", workers = 8)\nplan()\n\nmultisession:\n- args: function (..., workers = 8, envir = parent.frame())\n- tweaked: TRUE\n- call: plan(\"multisession\", workers = 8)\n\n\nWe’ll also set a seed at the start of the notebook so that we can reproduce our results if we decide to re-run this notebook at some future date. We also set future.globals.maxSize, see the Seurat future vignette linked above for discussion about why we do this (basically we might be exceeding the allowed global variable size so we make that default bigger).\n\nset.seed(61)\noptions(future.globals.maxSize = 4000 * 1024^2)"
  },
  {
    "objectID": "index.html#seurat-objects-overview",
    "href": "index.html#seurat-objects-overview",
    "title": "Introduction",
    "section": "0.7 Seurat objects overview",
    "text": "0.7 Seurat objects overview\n\n\n\n\n\n\nImportant\n\n\n\nIn November of 2023, Seurat made a major upgrade to Seurat v5 (https://github.com/satijalab/seurat/releases), which included many new functions and other changes (https://satijalab.org/seurat/articles/announcements.html#changes-in-seurat-v5), including some very big changes to the default behavior of Seurat. You will likely see different results depending on which version of Seurat you have used for your analysis. Feel free to come to our office hours if you want help setting up reproducible analyses using either version of Seurat.\n\n\nThis workshop focuses on using Seurat objects to structure your scRNA-seq data (https://github.com/satijalab/seurat/wiki/Seurat), we will attempt to cover how to interact with Seurat objects in Seurat v4 and v5, but won’t exhaustively cover the differences between the two versions.\nHere’s a schematic of a Seurat object:\n\n\n\nSchematic of a Seurat object\n\n\n\nEach Seurat object is composed of different components:\n\nassays is a list of all the assays in the object.\n\nDefaults to RNA assay, but you can add others (like SCT for normalizd counts, shown in the figure above, could also be antibody-derived tags, etc.).\nYou can see all assays using Assays(ifnb), see which assay is the currently active assay by looking in the active.assay slot (ifnb@active.assay) and switch between them using the DefaultAssay() function (DefaultAssay(ifnb) &lt;- 'RNA').\nEach assay will store multiple transformations of the data in different slots (or layers in Seurat v5) – in the case of RNA data these slots are:\n\n@counts contains the raw counts.\n@data contains the normalized counts.\n@scale.data contains the scaled data for dimensional reduction.\n\nThe slots (Seurat v4) or layers (Seurat v5) store the data as a sparse matrix where the rows are gene and the columns are cells.\nIn Seurat v4, you could access the raw counts like this:GetAssayData(ifnb, assay=\"RNA\", slot='counts'). This will still work in Seurat v5, but you’ll get a warning message. In Seurat v5 it is intended that you access the counts using the LayerData function, like this: LayerData(ifnb, assay='RNA', layer='counts')\nIn either version of Seurat ifnb[['RNA']]$counts will also work.\n\nmeta.data is a matrix of all the cell-level metadata.\n\nThis will include information about which condition, timepoint, batch, etc. a for a given cell.\nIt also includes metrics that will be relevant for QC, like nCount_RNA and nFeature_RNA\n\nnCount_RNA is the total number of molecules (UMIs) detected within a cell.\nnFeature_RNA is the total number of genes detected within a cell.\n\nOnce you have completed clustering, you’ll also see information about which cluster each cell has been assigned to.\nThe different categories or columns in the meta.data are also called Idents in Seurat.\nYou can see the current Ident in the active.ident slot (ifnb@active.ident) and switch between them using the Idents() function (this will probably be important for running differential expression testing).\nYou can use table(Idents(ifnb)) for a quick summary of the number of cells in each grouping.\n\ngraphs is a list of the nearest neighbor graphs.\n\nThe objects stored in graphs are cell x cell matrices containing the neighborhood overlap (Jaccard index) between every cell and its nearest neighbors.\n\nreductions is a list of DimReduc objects.\nversion contains information about which version of Seurat was used to make the object.\nThere are other optional slots, including tools and misc that can be populated by specific analysis tools (tools) or users can store their own additional information (misc)."
  },
  {
    "objectID": "index.html#importing-data-and-interacting-with-seurat-objects",
    "href": "index.html#importing-data-and-interacting-with-seurat-objects",
    "title": "Introduction",
    "section": "0.8 Importing data and interacting with Seurat objects",
    "text": "0.8 Importing data and interacting with Seurat objects\nMuch of this notebook is taken from the various Seurat vignettes: https://satijalab.org/seurat/articles/get_started.html\nFirst, load all the libraries we need, including some Seurat data packages. The last line will update the Seurat objects so that they are compatible with the newest version of Seurat.\n\n.libPaths(c('/usr/local/lib/R/site-library', '/usr/local/lib/R/library'))\n\nlibrary(RColorBrewer)\nlibrary(Seurat)\nlibrary(patchwork)\n#library(ggplot2)\nlibrary(dplyr)\nlibrary(hdf5r)\nlibrary(stringr)\nlibrary(biomaRt)\n#library(viridis)\n#library(SeuratDisk)\nlibrary(SeuratData)\n#library(msigdbr)\n#library('pbmc3k.SeuratData')\n#library('cbmc.SeuratData')\nlibrary('ifnb.SeuratData')\n#data(\"pbmc3k\")\n#data(\"cbmc\")\ndata(\"ifnb\")\nifnb &lt;- UpdateSeuratObject(ifnb)\ndata(\"pbmc3k\")\npbmc3k &lt;- UpdateSeuratObject(pbmc3k)\n\n\nWe are using the SeuratData package for some test data.\nUse AvailableData() to see what datasets are available\n\n\nSeuratData::AvailableData() %&gt;% data.frame() %&gt;% head()\n\n                                   Dataset Version\nadiposeref.SeuratData           adiposeref   1.0.0\nbmcite.SeuratData                   bmcite   0.3.0\nbonemarrowref.SeuratData     bonemarrowref   1.0.0\ncbmc.SeuratData                       cbmc   3.1.4\ncelegans.embryo.SeuratData celegans.embryo   0.1.0\nfetusref.SeuratData               fetusref   1.0.0\n                                                                          Summary\nadiposeref.SeuratData                                  Azimuth Reference: adipose\nbmcite.SeuratData                                           30k Bone Marrow Cells\nbonemarrowref.SeuratData                            Azimuth Reference: bonemarrow\ncbmc.SeuratData                      scRNAseq and 13-antibody sequencing of CBMCs\ncelegans.embryo.SeuratData 6k C. elegans embryos from Packer and Zhu et al (2019)\nfetusref.SeuratData                                      Azimuth Reference: fetus\n                              species            system ncells\nadiposeref.SeuratData           human           adipose 160075\nbmcite.SeuratData               human       bone marrow  30672\nbonemarrowref.SeuratData        human        bonemarrow 297627\ncbmc.SeuratData                 human CBMC (cord blood)   8617\ncelegans.embryo.SeuratData C. elegans            embryo   6188\nfetusref.SeuratData             human             fetus 377456\n                                             tech seurat default.dataset\nadiposeref.SeuratData      scRNA-seq and sNuc-seq   &lt;NA&gt;            &lt;NA&gt;\nbmcite.SeuratData                            &lt;NA&gt;  3.2.2            &lt;NA&gt;\nbonemarrowref.SeuratData                   10x v2   &lt;NA&gt;            &lt;NA&gt;\ncbmc.SeuratData                          CITE-seq  3.1.4             raw\ncelegans.embryo.SeuratData                   &lt;NA&gt;   &lt;NA&gt;             raw\nfetusref.SeuratData                          &lt;NA&gt;   &lt;NA&gt;            &lt;NA&gt;\n                           disk.datasets other.datasets notes Installed\nadiposeref.SeuratData               &lt;NA&gt;           &lt;NA&gt;  &lt;NA&gt;     FALSE\nbmcite.SeuratData                   &lt;NA&gt;           &lt;NA&gt;  &lt;NA&gt;     FALSE\nbonemarrowref.SeuratData            &lt;NA&gt;           &lt;NA&gt;  &lt;NA&gt;     FALSE\ncbmc.SeuratData                processed           &lt;NA&gt;  &lt;NA&gt;     FALSE\ncelegans.embryo.SeuratData          &lt;NA&gt;           &lt;NA&gt;  &lt;NA&gt;     FALSE\nfetusref.SeuratData                 &lt;NA&gt;           &lt;NA&gt;  &lt;NA&gt;     FALSE\n                           InstalledVersion\nadiposeref.SeuratData                  &lt;NA&gt;\nbmcite.SeuratData                      &lt;NA&gt;\nbonemarrowref.SeuratData               &lt;NA&gt;\ncbmc.SeuratData                        &lt;NA&gt;\ncelegans.embryo.SeuratData             &lt;NA&gt;\nfetusref.SeuratData                    &lt;NA&gt;\n\nSeuratData::AvailableData() %&gt;% data.frame() %&gt;% dplyr::filter(Installed == 'TRUE')\n\n                  Dataset Version                           Summary species\nifnb.SeuratData      ifnb   3.1.0 IFNB-Stimulated and Control PBMCs   human\npbmc3k.SeuratData  pbmc3k   3.1.4        3k PBMCs from 10X Genomics   human\n                  system ncells   tech seurat default.dataset disk.datasets\nifnb.SeuratData     PBMC  13999 10x v1   &lt;NA&gt;             raw          &lt;NA&gt;\npbmc3k.SeuratData   PBMC   2700 10x v1  3.1.4             raw          &lt;NA&gt;\n                  other.datasets notes Installed InstalledVersion\nifnb.SeuratData        processed  &lt;NA&gt;      TRUE            3.1.0\npbmc3k.SeuratData   pbmc3k.final  &lt;NA&gt;      TRUE            3.1.4\n\n\n\nWe’ve already installed some test data in this container. You would usually be able to install more data sets using InstallData but won’t have permissions to install in this container.\nIt is more likely that you are using Seurat with your own data – you can use the functions Read10X or Read10X_h5 to import data.\nRead10X_h5 works with H5 files – “Hierarchical Data Format (HDF5 or H5). H5 is a binary format that can compress and access data much more efficiently than text formats such as MEX, which is especially useful when dealing with large datasets.” https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/h5_matrices.\nYou can also use Read10X and give a path to a folder that contains your matrix, features, and barcode tsv files.\nAfter you have read in the 10X data, use it as the input to the CreateSeuratObject function.\n\nAs an aside, you can also import counts matrix data from GEO using something like this function I wrote based on a biostars post (although I make no guarantees that this will work with everything from GEO – proceed with caution and feel free to come by office hours for help if this is something you need to do):\n\n#https://www.biostars.org/p/9527335/#9527339\ncounts_to_seurat &lt;- function(matrix_path, project){\n  \n  #use fread to import the data\n  mat &lt;- data.table::fread(matrix_path)\n\n  #set rownames to be the first column of gene IDs\n  rownames(mat) &lt;- mat$V1 \n  \n  #make `mat` be only numeric data by removing column of gene IDs\n  mat$V1 &lt;- NULL\n\n  #create Seurat object\n  seu &lt;- CreateSeuratObject(counts = mat, \n                            project = project)\n  \n  return(seu)\n}\n\nE12_JS_14 &lt;- counts_to_seurat(matrix_path = '/data/cbc/Dennery_scRNAseq/dennery_2023_grant/GSE165063/GSM5025543_E12_JS-14_processed_counts.csv', project = 'E12_JS_14')\n\nWe can look at the Seurat object we’ve loaded from SeuratData:\n\n?ifnb\n\nThe ifnb dataset is 14,000 IFNB-Stimulated and Control PBMCs (peripheral blood mononuclear cells).\n\nifnb\n\nAn object of class Seurat \n14053 features across 13999 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 2 layers present: counts, data\n\n\nWe can also see that Seurat v5 assays store data in layers. These layers can store raw, un-normalized counts (layer=‘counts’), normalized data (layer=‘data’) or z-scored/variance-stabilized data (layer=‘scale.data’). What assays and meta.data are available?\n\nifnb@assays\n\n$RNA\nAssay data with 14053 features for 13999 cells\nFirst 10 features:\n AL627309.1, RP11-206L10.2, LINC00115, NOC2L, KLHL17, PLEKHN1, HES4,\nISG15, AGRN, C1orf159 \n\nhead(ifnb@meta.data)\n\n                  orig.ident nCount_RNA nFeature_RNA stim seurat_annotations\nAAACATACATTTCC.1 IMMUNE_CTRL       3017          877 CTRL          CD14 Mono\nAAACATACCAGAAA.1 IMMUNE_CTRL       2481          713 CTRL          CD14 Mono\nAAACATACCTCGCT.1 IMMUNE_CTRL       3420          850 CTRL          CD14 Mono\nAAACATACCTGGTA.1 IMMUNE_CTRL       3156         1109 CTRL                pDC\nAAACATACGATGAA.1 IMMUNE_CTRL       1868          634 CTRL       CD4 Memory T\nAAACATACGGCATT.1 IMMUNE_CTRL       1581          557 CTRL          CD14 Mono\n\n\nWe have an RNA assay, information about which experimental condition the cell came from (orig.ident and stim), the number of genes (nFeature_RNA) and molecules (nCount_RNA) in each cell. This particular object also comes pre-annotated (seurat_annotations).\nWe will aim to eventually integrate the different samples (IMMUNE_CTRL and IMMUNE_STIM from orig.ident) together. In previous versions of Seurat, we would require the data to be represented as a list of different Seurat objects. When using Seurat v5 assays, we can instead keep all the data in one object, but simply split the layers.\n\nifnb[[\"RNA\"]] &lt;- split(ifnb[[\"RNA\"]], f = ifnb$orig.ident)\n\nWarning: Input is a v3 assay and `split()` only works for v5 assays; converting\n• to a v5 assay\n\n\nWarning: Assay RNA changing from Assay to Assay5\n\nifnb\n\nAn object of class Seurat \n14053 features across 13999 samples within 1 assay \nActive assay: RNA (14053 features, 0 variable features)\n 4 layers present: counts.IMMUNE_CTRL, counts.IMMUNE_STIM, data.IMMUNE_CTRL, data.IMMUNE_STIM\n\n\nAfter splitting, there are now 4 layers (a counts and data layer for each batch). Since the data is split into layers, normalization and variable feature identification is performed for each sample independently (a consensus set of variable features is automatically identified)."
  },
  {
    "objectID": "index.html#data-merging",
    "href": "index.html#data-merging",
    "title": "Introduction",
    "section": "0.9 Data merging",
    "text": "0.9 Data merging\nIn addition to ifnb, we have also installed pbmc3k, which is from 2,700 peripheral blood mononuclear cells (PBMC) from 10X genomics.\n\n?pbmc3k\npbmc3k@assays\n\n$RNA\nAssay data with 13714 features for 2700 cells\nFirst 10 features:\n AL627309.1, AP006222.2, RP11-206L10.2, RP11-206L10.9, LINC00115, NOC2L,\nKLHL17, PLEKHN1, RP11-54O7.17, HES4 \n\nhead(pbmc3k@meta.data)\n\n               orig.ident nCount_RNA nFeature_RNA seurat_annotations\nAAACATACAACCAC     pbmc3k       2419          779       Memory CD4 T\nAAACATTGAGCTAC     pbmc3k       4903         1352                  B\nAAACATTGATCAGC     pbmc3k       3147         1129       Memory CD4 T\nAAACCGTGCTTCCG     pbmc3k       2639          960         CD14+ Mono\nAAACCGTGTATGCG     pbmc3k        980          521                 NK\nAAACGCACTGGTAC     pbmc3k       2163          781       Memory CD4 T\n\n\n\nFirst, lets subset our datasets so they are smaller and easier to work with for this workshop.\n\n\npbmc3k &lt;- subset(pbmc3k, downsample = 300)\nifnb &lt;- subset(ifnb, downsample = 700)\n\n\nLet’s merge the datasets to make our QC and filtering a bit smoother.\nmerge() merges the raw count matrices of two Seurat objects and creates a new Seurat object with the resulting combined raw count matrix.\nTo easily tell which original object any particular cell came from, you can set the add.cell.ids parameter with an c(x, y) vector, which will prepend the given identifier to the beginning of each cell name.\nThe original project ID will remain stored in object meta data under orig.ident.\n\n\nall_data &lt;- merge(x = ifnb, y = pbmc3k, add.cell.ids = c(\"ifnb\", \"pbmc3k\"), project = 'pbmc')"
  },
  {
    "objectID": "index.html#data-qc",
    "href": "index.html#data-qc",
    "title": "Introduction",
    "section": "0.10 Data QC",
    "text": "0.10 Data QC\n\nWe care about the percentage of reads that map to the mitochondrial genome because high mitochondrial reads in a cell can indicate that the cells are low-quality or dying cells\nThe mitochondrial QC metrics are calcualted with the PercentageFeatureSet() function, which calculates the percentage of counts originating from a set of features\nWe use the set of all genes starting with MT- as a set of mitochondrial genes – the format of the mt sequences will vary depending on which organism/genome is used…(might be ‘mt-’ for example).\n\n\nrownames(all_data) %&gt;% grep(pattern = '^mt-', ignore.case = TRUE, value = TRUE)\n\n [1] \"MT-ND1\"  \"MT-ND2\"  \"MT-CO1\"  \"MT-CO2\"  \"MT-ATP8\" \"MT-ATP6\" \"MT-CO3\" \n [8] \"MT-ND3\"  \"MT-ND4L\" \"MT-ND4\"  \"MT-ND5\"  \"MT-ND6\"  \"MT-CYB\" \n\n\n\nall_data[[\"percent.mt\"]] &lt;- PercentageFeatureSet(all_data, pattern = \"^MT-\")\n\n\nBefore we plot, we can set the order of the object idents to whatever order we’d like:\n\n\nIdents(all_data) &lt;- 'orig.ident'\nlevels(all_data) &lt;- c(\"pbmc3k\", \"IMMUNE_CTRL\", \"IMMUNE_STIM\")\n\n\nWe can also look at plots showing the distribution of the percent.mt, nFeature_RNA and nCount_RNA\nnFeature_RNA is the number of genes\nnCount_RNA is the number of UMIs (unique molecules – like counts)\n\n\nVlnPlot(all_data, features = \"nFeature_RNA\")\n\n\n\n\n\nVlnPlot(all_data, features = \"nCount_RNA\")\n\n\n\n\n\nVlnPlot(all_data, features=\"percent.mt\")\n\n\n\n\n\nFeatureScatter(all_data, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")\n\n\n\n\n\nFeatureScatter(all_data, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")\n\n\n\n\n\nFeatureScatter(all_data, feature1 = \"nFeature_RNA\", feature2 = \"percent.mt\")\n\n\n\n\nYou can also just use ggplot to make your own custom visualizations of the information in the metadata. We make a separate matrix called qc_data and sorting it based on the percent.mt column. Then we make our own ggplot and specify that the x and y axes should be nCount_RNA and nFeature_RNA and that the points should be colored based on percent.mt. Then, use scale_color_gradientn to specify how the points should be colored, specifying that the limit should be between 0 and 10 and that we should squish anything that is out of bounds (effectively making our limits 0 and &gt;10).\n\nqc_data &lt;- all_data@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %&gt;% arrange(percent.mt)\n\nggplot2::ggplot(qc_data, ggplot2::aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + \n  ggplot2::geom_point() + \n ggplot2:: scale_color_gradientn(colors = rev(brewer.pal(5, \"Spectral\")), limits = c(0,10), oob = (scales::squish)) +\n  ggplot2::facet_wrap(~orig.ident) + \n  ggplot2::theme_bw()\n\n\n\n\n\nLow quality cells or empty droplets might have very few genes (nFeatures)\nDead or dying cells will also have high mitochondrial reads (percent.mt)\nDoublets or multiplets will have high gene counts (nFeatures)\nThe total number of molecules (nCount) detected in a cell corresponds with the number of genes (nFeatures)\nMost of the cells have less than 2000 genes and less than 7000 or so UMIs.\nVery low mitochondrial counts from the ifnb data and the nFeature_RNA scatter plots look strange – perhaps this dataset was pre-filtered before being packaged into SeuratData.\nIn the pbmc3k data, we can see groups of cells with high mitochondrial counts, low UMI counts, and lower numbers of genes.\nOur goal in QC filtering is to retain as much useful information as we can, while removing doublets, empty droplets, and dead cells.\nWe will pick some thresholds for filtering based off of what we see in our data, keeping in mind that if you are doing this with your own data, your plots will probably look a bit different."
  },
  {
    "objectID": "index.html#data-filtering",
    "href": "index.html#data-filtering",
    "title": "Introduction",
    "section": "0.11 Data Filtering",
    "text": "0.11 Data Filtering\n\nLet’s filter our data using subset, we’ll keep cells that have between 500 and 7000 nFeature_RNA (genes) and less than 5% mitochondrial reads.\n\n\nall_data_sub &lt;- subset(all_data, subset = nFeature_RNA &gt; 500 & nFeature_RNA &lt; 7000 & percent.mt &lt; 5)\n\n\nYou can re-examine your QC plots after filtering if you’d like:\n\n\nqc_data_sub &lt;- all_data_sub@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %&gt;% arrange(percent.mt)\n\nggplot2::ggplot(qc_data_sub,ggplot2:: aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + \n  ggplot2::geom_point() + \n  ggplot2::scale_color_gradientn(colors = rev(brewer.pal(5, \"Spectral\")), limits = c(0,10), oob = (scales::squish)) +\n  ggplot2::facet_wrap(~orig.ident) + \n  ggplot2::theme_bw()\n\n\n\n\n\nWe can also take a look at how many cells we lost from filtering (245 cells lost from pbmc3k).\n\n\ntable(all_data@meta.data$orig.ident)\n\n\nIMMUNE_CTRL IMMUNE_STIM      pbmc3k \n        700         700         300 \n\ntable(all_data_sub@meta.data$orig.ident)\n\n\nIMMUNE_CTRL IMMUNE_STIM      pbmc3k \n        700         700         270"
  },
  {
    "objectID": "index.html#normalization",
    "href": "index.html#normalization",
    "title": "Introduction",
    "section": "0.12 Normalization",
    "text": "0.12 Normalization\n\n0.12.1 Theory\nscRNAseq data is normalized so that we can mitigate technical effects while preserving the biological signal in the data – we should be able to find the biological signal in cells irrespective of how deeply we sequenced the cell. The theory behind SCTransform (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) is very similar to the generalized linear models (GLMs) used in bulk RNAseq analysis packages like DESeq2 and edgeR. In DESeq2 a negative binomial model is fitted to the counts and the mean and dispersion (roughly speaking how variable the observed count will be from the mean count) estimates from that model are used as the test statistics for comparison between groups. The same idea applies with SCTransform, with an additional aspect where SCTransform pools information across genes with similar abundances in order to address the higher sparsity of single cell data.\nBelow is a side-by-side comparison of sctransform with NormalizeData, FindVariableFeatures and ScaleData on the PBMC3k data:\n\n\n\nsct\n\n\nWe also like this figure from the SCTransform paper, which shows how SCTransform (‘Pearson Residuals’) and the standard log-transformation approach (‘Log-normalization’) helps alleviate variance in your data from sequencing depth alone :\n\n\n\nsct_fig6\n\n\n\n\n0.12.2 When should you not use SCTransform?\nThe paper states:\nAs our workflow leverages all genes (or a random sub-set) for the initial regularization, we make an implicit assumption that the majority of genes in the dataset do not exhibit significant biological variation...this assumption may be overly simplistic when performing scRNA-seq on a highly heterogeneous sample, we did not observe adverse affects when applying our model to human PBMC data, or any of the other datasets we examined.\nSCTransform might not work well if your data is highly heterogeneous and you expect that a high proportion of genes will exhibit significant biological variation across your samples. In this case, we would recommend the more standard workflow of NormalizeData, FindVariableFeatures, and ScaleData.\n\n\n0.12.3 SCTransform versions\nSeurat v5 runs SCTransform v2 (https://satijalab.org/seurat/archive/v4.3/sctransform_v2_vignette) by default, while Seurat v4 runs SCTransform v1 by default. SCTransform v2 “improves speed and memory consumption, the stability of parameter estimates, the identification of variable features, and the the ability to perform downstream differential expression analyses.” This means you might get different results if you run Seurat v5 and re-normalize data that you have previously processed with Seurat v4. If you want to change from the default veresion of SCTransform, you can add the argument vst.flavor = \"v1\" (or vst.flavor = \"v2\"))\n\n\n0.12.4 Running SCTransform\nWe will normalize using SCTransform and you might get see a warning that says ‘iteration limit reached’ when you run the function. This warning can be ignored (https://github.com/satijalab/sctransform/issues/25) because the parameter estimation generating this warning is regularized later anyway. You can use the vars.to.regress argument to regress out nuisance variables (like cell cycle, batch effects, or percent.mt). By default SCTransform will only return data for variable genes in the scale data slot – adding the return.only.var.genes = FALSE argument to the function call to turn this option off (https://github.com/satijalab/seurat/issues/3553). In previous versions of Seurat, you would have to split your object into a list of Seurat objects based on the orig.ident and then run SCTransform on the list, which is not necessary in Seurat v5.\n\nstart.time &lt;- Sys.time()\nall_data_sub &lt;- SCTransform(all_data_sub, vars.to.regress = \"percent.mt\", verbose = FALSE, return.only.var.genes = FALSE)\nend.time &lt;- Sys.time()\nend.time - start.time\n\nTime difference of 2.525375 mins\n\n\nThen run PCA\n\nall_data_sub &lt;- RunPCA(all_data_sub)\n\nWarning in PrepDR(object = object, features = features, verbose = verbose): The\nfollowing 134 features requested have not been scaled (running reduction\nwithout them): CCL2, VMO1, CCL7, CXCL10, IDO1, MIR155HG, HBB, C15orf48, CXCL3,\nHBA2, HBA1, SDS, TNFAIP6, CXCL11, SERPINB2, IL1RN, DUSP4, CYP1B1, PLA2G7,\nRAMP1, FCER1A, TCL1A, TVP23A, CCL22, HSPA1B, RP11-701P16.5, XCL2, LAG3, TYW3,\nSESN3, THBS1, IL1R2, CENPF, HPSE, IL4I1, HBEGF, CD200, GADD45G, GNG11, CCL23,\nRP1-313I6.12, RAPGEF2, CCL3L1, SDPR, OLR1, PRR5, MZB1, SERPINF1, P2RY6, POLR1C,\nDHRS9, SMC6, L3MBTL3, MAP3K7CL, SCML1, ANKRD22, ASNS, IL2RB, SLC25A19, VPS45,\nDNAJB4, LINC00998, CAMK1, TLR1, SLC7A11, CTNNAL1, CCR5, RP11-664D1.1, ZBP1,\nXIST, SPHK1, TNFSF14, CCRL2, LINC00996, ANPEP, NAPG, TRNT1, RAB30-AS1, AQP9,\nCCL8, CXCL1, NUPR1, LINC00926, C1QB, VPREB3, ID1, NCR3, FCER2, SPINK1, MT-ND2,\nSPP1, MT-CYB, CTD-2035E11.3, FCGR3B, TNFRSF13B, RFNG, FASLG, SPIB, EDN1, ENHO,\nMT-CO2, RBP7, RNASE1, NQO1, AL928768.3, ANKRD37, C19orf59, CH25H, IGFBP4,\nFCRL6, ABHD5, AP003733.1, MMP9, NMB, KIAA0125, PKIB, PSAT1, MT-ATP6, DDX20,\nC16orf74, HRASLS2, EIF1AY, MASTL, RPAP2, EBI3, SECISBP2L, SCT, RGS18, FOXN2,\nCHCHD4, PMP22, IRAK2, FRMD4B, IL10\n\n\nPC_ 1 \nPositive:  FTL, TIMP1, FTH1, SOD2, LYZ, TYROBP, FCER1G, CST3, APOBEC3A, S100A8 \n       S100A9, LGALS1, LGALS3, S100A4, HLA-DRA, CD63, TYMP, IL8, S100A11, ANXA5 \n       IFITM3, FCN1, SAT1, CTSL, CTSB, S100A10, HLA-DRB1, ANXA2, MS4A7, PSAP \nNegative:  RPL3, RPS18, RPS6, RPL13, RPL13A, LTB, RPL21, CCR7, RPS2, RPS4X \n       RPL34, RPS3, GIMAP7, RPS27A, RPL7, RPS14, RPL10, RPS3A, CD3D, RPL32 \n       LDHB, RPS15A, RPS27, RPL10A, PTMA, RPS12, RPS5, RPS19, RPSA, RPL9 \nPC_ 2 \nPositive:  RPS18, RPL34, RPL13, RPL3, RPS14, RPS4X, LTB, RPL10, RPL32, RPL13A \n       RPS6, RPS12, RPL7, RPL21, RPS2, LDHB, RPS15A, RPS3, PABPC1, RPL31 \n       CD3D, RPL11, RPS3A, RPS27A, GIMAP7, RPL10A, RPS27, GIMAP5, RPS13, RPSA \nNegative:  CD74, HLA-DRA, NKG7, GZMB, HLA-DQA1, CCL5, GNLY, HLA-DRB1, HLA-DPB1, CST7 \n       HLA-DPA1, HLA-DQB1, CD83, HERPUD1, PRF1, GZMA, PMAIP1, REL, CD69, HSPD1 \n       HSPE1, SRSF7, APOBEC3G, HSP90AB1, RAN, SRSF2, CTSW, DUSP2, GZMH, BIRC3 \nPC_ 3 \nPositive:  HLA-DRA, CD74, HLA-DQA1, HLA-DRB1, HLA-DPB1, HLA-DPA1, HLA-DQB1, CD79A, CCR7, CD83 \n       MS4A1, HLA-DMA, HERPUD1, IRF8, LYZ, TXN, NPM1, MYC, NME1, SYNGR2 \n       HLA-DRB5, REL, FABP5, RPL18A, RPS18, RPS5, ID3, BIRC3, RPL10A, RPL13 \nNegative:  NKG7, CCL5, GNLY, GZMB, PRF1, GZMA, CTSW, GZMH, APOBEC3G, CST7 \n       FGFBP2, CLIC3, KLRD1, RARRES3, FCGR3A, CD247, CCL4, CD7, IL32, CD8A \n       HLA-A, HLA-C, CHST12, ALOX5AP, CXCR3, GZMM, HOPX, SH2D2A, CD2, C1orf21 \nPC_ 4 \nPositive:  SRSF2, DDIT4, CACYBP, CREM, SRSF7, HSPA8, CD69, S100A8, HSPH1, S100A9 \n       TRAT1, NOP58, FTL, CLK1, H3F3B, YPEL5, HSPB1, TSC22D3, ZFAS1, SOD1 \n       JUNB, HSPE1, ATF4, PIK3IP1, CCNL1, HSPD1, UBC, NFKBIA, ZFAND2A, EIF5 \nNegative:  CD74, HLA-DRA, HLA-DPB1, NKG7, HLA-DPA1, CCL5, GNLY, GZMB, CST7, HLA-DRB1 \n       HLA-DQA1, HLA-DQB1, CD79A, APOBEC3G, CLIC3, CTSW, PRF1, GZMH, GZMA, FGFBP2 \n       HLA-DMA, ALOX5AP, RPL3, CHST12, MS4A1, HLA-C, RPS2, RPS4X, PTPRCAP, SYNGR2 \nPC_ 5 \nPositive:  FCGR3A, MS4A7, MS4A4A, TNFSF10, FAM26F, LST1, AIF1, CXCL16, IFITM2, GBP1 \n       IFITM3, PLAC8, GBP5, HN1, CTSC, ATP1B3, WARS, CFD, SERPINA1, GBP2 \n       TNFSF13B, FGL2, MT2A, C3AR1, RGS2, CD86, CTSS, VAMP5, TIMP1, IFIT3 \nNegative:  S100A8, S100A9, IL8, LYZ, CD63, GPX1, LGALS1, FTL, LGALS3, S100A10 \n       VIM, CTSB, GAPDH, CCL5, MARCKSL1, CSTB, NKG7, SH3BGRL3, CXCL2, CD14 \n       CAPG, GZMB, HSPA5, TALDO1, CST7, VCAN, LMNA, GNLY, CTSL, TXN \n\n\nWe can make an elbow plot:\n\nElbowPlot(all_data_sub)\n\n\n\n\nBased on this plot, we get diminishing information returned once we get above ~10-15 PCs. We will use this information when we run clustering."
  },
  {
    "objectID": "index.html#integration",
    "href": "index.html#integration",
    "title": "Introduction",
    "section": "0.13 Integration",
    "text": "0.13 Integration\nIntegration of single-cell sequencing datasets, for example across experimental batches, donors, or conditions, is often an important step in scRNA-seq workflows. Integrative analysis can help to match shared cell types and states across datasets, which can boost statistical power, and most importantly, facilitate accurate comparative analysis across datasets. In previous versions of Seurat we introduced methods for integrative analysis, including our ‘anchor-based’ integration workflow. Many labs have also published powerful and pioneering methods, including Harmony and scVI, for integrative analysis. We recognize that while the goal of matching shared cell types across datasets may be important for many problems, users may also be concerned about which method to use, or that integration could result in a loss of biological resolution. In Seurat v5, we introduce more flexible and streamlined infrastructure to run different integration algorithms with a single line of code. This makes it easier to explore the results of different integration methods, and to compare these results to a workflow that excludes integration steps.\nSeurat v5 enables streamlined integrative analysis using the IntegrateLayers function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches (samples):\nAnchor-based CCA integration (method=CCAIntegration)\nAnchor-based RPCA integration (method=RPCAIntegration)\nHarmony (method=HarmonyIntegration)\nFastMNN (method= FastMNNIntegration)\nscVI (method=scVIIntegration)\nA detailed discussion of these different methods is outside the scope of this workshop, but you can find more detail on each method in Seurat’s documentation. However, the Seurat authors state:\nBy identifying shared sources of variation between datasets, CCA is well-suited for identifying anchors when cell types are conserved, but there are very substantial differences in gene expression across experiments. CCA-based integration therefore enables integrative analysis when experimental conditions or disease states introduce very strong expression shifts, or when integrating datasets across modalities and species. However, CCA-based integration may also lead to overcorrection, especially when a large proportion of cells are non-overlapping across datasets. RPCA-based integration runs faster, and also represents a more conservative approach where cells in different biological states are less likely to ‘align’ after integration. We therefore recommend RPCA during integrative analysis where:\n\nA substantial fraction of cells in one dataset have no matching type in the other\nDatasets originate from the same platform (i.e. multiple lanes of 10x genomics)\nThere are a large number of datasets or cells to integrate (see here for more tips on integrating large datasets)\n\nThere are also papers that attempt to benchmark different integration approaches:\n“For example, the use of Harmony is appropriate for simple integration tasks with distinct batch and biological structure; however, this method typically ranks outside the top three when used for complex real data scenarios… Methods that used cell annotations to integrate batches (scGen and scANVI) performed well across tasks…Particularly in more complex integration tasks, we observed a tradeoff between batch effect removal and bio-conservation (Fig. 3a and Supplementary Data 1). While methods such as SAUCIE, LIGER, BBKNN and Seurat v3 tend to favor the removal of batch effects over conservation of biological variation, DESC and Conos make the opposite choice, and Scanorama, scVI and FastMNN (gene) balance these two objectives. Other methods strike different balances per task (Extended Data Fig. 4). This tradeoff is particularly noticeable where biological and batch effects overlap. For example, in the lung task, three datasets sample two distinct spatial locations (airway and parenchyma). Particular cell types such as endothelial cells perform different functions in these locations (for example, gas exchange in the parenchyma).” (Luecken et al 2022 https://doi.org/10.1038/s41592-021-01336-8).\nWe will run CCAIntegration (this was the default flavor of integration in previous versions of Seurat), RPCAIntegration, and HarmonyIntegration. Note that we are specifying that we used SCT normalization:\n\nall_data_sub&lt;- IntegrateLayers(\n  object = all_data_sub, method = CCAIntegration,\n  orig.reduction = \"pca\", new.reduction = \"integrated.cca\", normalization.method = \"SCT\",\n  verbose = FALSE\n)\n\n\nall_data_sub &lt;- IntegrateLayers(\n  object = all_data_sub, method = RPCAIntegration,\n  orig.reduction = \"pca\", new.reduction = \"integrated.rpca\", normalization.method = \"SCT\",\n  verbose = FALSE\n)\n\n\nall_data_sub &lt;- IntegrateLayers(\n  object = all_data_sub, method = HarmonyIntegration,\n  orig.reduction = \"pca\", new.reduction = \"harmony\", normalization.method = \"SCT\",\n  verbose = FALSE\n)\n\nWarning: HarmonyMatrix is deprecated and will be removed in the future from the\nAPI in the future\n\n\nWarning: Warning: The parameters do_pca and npcs are deprecated. They will be ignored for this function call and please remove parameters do_pca and npcs and pass to harmony cell_embeddings directly.\nThis warning is displayed once per session.\n\n\nWarning: Warning: The parameter tau is deprecated. It will be ignored for this function call and please remove parameter tau in future function calls. Advanced users can set value of parameter tau by using parameter .options and function harmony_options().\nThis warning is displayed once per session.\n\n\nWarning: Warning: The parameter block.size is deprecated. It will be ignored for this function call and please remove parameter block.size in future function calls. Advanced users can set value of parameter block.size by using parameter .options and function harmony_options().\nThis warning is displayed once per session.\n\n\nWarning: Warning: The parameter max.iter.harmony is replaced with parameter max_iter. It will be ignored for this function call and please use parameter max_iter in future function calls.\nThis warning is displayed once per session.\n\n\nWarning: Warning: The parameter max.iter.cluster is deprecated. It will be ignored for this function call and please remove parameter max.iter.cluster in future function calls. Advanced users can set value of parameter max.iter.cluster by using parameter .options and function harmony_options().\nThis warning is displayed once per session.\n\n\nWarning: Warning: The parameter epsilon.cluster is deprecated. It will be ignored for this function call and please remove parameter epsilon.cluster in future function calls. Advanced users can set value of parameter epsilon.cluster by using parameter .options and function harmony_options().\nThis warning is displayed once per session.\n\n\nWarning: Warning: The parameter epsilon.harmony is deprecated. It will be ignored for this function call and please remove parameter epsilon.harmony in future function calls. If users want to control if harmony would stop early or not, use parameter early_stop. Advanced users can set value of parameter epsilon.harmony by using parameter .options and function harmony_options().\nThis warning is displayed once per session.\n\n\nSeurat will cluster your cells into groups of cells with similar expression patterns. The first step is FindNeighbors, which will construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). To cluster the cells, we run FindClusters to apply the Louvain algorithm to iteratively group cells together, with the goal of optimizing the standard modularity function. FindClusters takes a resolution argument (defaults to a value of 0.8), which sets the granularity of the clustering, setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells but the resolution might increase for larger datasets. Use a value above 1 if you want a larger number of communities (clusters), and a value below 1 if you want a smaller number of communities.\n\nall_data_sub &lt;- FindNeighbors(all_data_sub, reduction = \"integrated.cca\", dims = 1:10)\n\nComputing nearest neighbor graph\n\n\nComputing SNN\n\nall_data_sub &lt;- FindClusters(all_data_sub, resolution = .6, cluster.name = \"cca_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 1670\nNumber of edges: 59208\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8616\nNumber of communities: 9\nElapsed time: 0 seconds\n\nall_data_sub &lt;- FindNeighbors(all_data_sub, reduction = \"integrated.rpca\", dims = 1:10)\n\nComputing nearest neighbor graph\nComputing SNN\n\nall_data_sub &lt;- FindClusters(all_data_sub, resolution = .6, cluster.name = \"rpca_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 1670\nNumber of edges: 56912\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8595\nNumber of communities: 9\nElapsed time: 0 seconds\n\nall_data_sub &lt;- FindNeighbors(all_data_sub, reduction = \"harmony\", dims = 1:10)\n\nComputing nearest neighbor graph\nComputing SNN\n\nall_data_sub &lt;- FindClusters(all_data_sub, resolution = .6, cluster.name = \"harmony_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 1670\nNumber of edges: 57828\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8597\nNumber of communities: 9\nElapsed time: 0 seconds\n\n\nRun UMAP (Uniform Manifold Approximation and Projection) dimensional reduction technique on the unintegrated data and the different integration methods:\n\nall_data_sub &lt;- RunUMAP(all_data_sub, dims = 1:10, reduction = \"pca\", reduction.name = \"umap.unintegrated\")\n\nWarning: The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric\nTo use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'\nThis message will be shown once per session\n\n\n15:26:05 UMAP embedding parameters a = 0.9922 b = 1.112\n\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\n\n\nAlso defined by 'BiocGenerics'\n\n\n15:26:05 Read 1670 rows and found 10 numeric columns\n\n\n15:26:05 Using Annoy for neighbor search, n_neighbors = 30\n\n\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\n\n\nAlso defined by 'BiocGenerics'\n\n\n15:26:05 Building Annoy index with metric = cosine, n_trees = 50\n\n\n0%   10   20   30   40   50   60   70   80   90   100%\n\n\n[----|----|----|----|----|----|----|----|----|----|\n\n\n**************************************************|\n15:26:05 Writing NN index file to temp file /tmp/Rtmp7eCxNF/file1c38c82b53fdfd\n15:26:05 Searching Annoy index using 8 threads, search_k = 3000\n15:26:05 Annoy recall = 100%\n15:26:06 Commencing smooth kNN distance calibration using 8 threads with target n_neighbors = 30\n15:26:07 Initializing from normalized Laplacian + noise (using RSpectra)\n15:26:07 Commencing optimization for 500 epochs, with 64818 positive edges\n15:26:10 Optimization finished\n\nall_data_sub &lt;- RunUMAP(all_data_sub, reduction = \"integrated.cca\", dims = 1:10, reduction.name = \"umap.cca\")\n\n15:26:10 UMAP embedding parameters a = 0.9922 b = 1.112\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\nAlso defined by 'BiocGenerics'\n15:26:10 Read 1670 rows and found 10 numeric columns\n15:26:10 Using Annoy for neighbor search, n_neighbors = 30\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\nAlso defined by 'BiocGenerics'\n15:26:10 Building Annoy index with metric = cosine, n_trees = 50\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\n15:26:10 Writing NN index file to temp file /tmp/Rtmp7eCxNF/file1c38c873140f8\n15:26:10 Searching Annoy index using 8 threads, search_k = 3000\n15:26:10 Annoy recall = 100%\n15:26:11 Commencing smooth kNN distance calibration using 8 threads with target n_neighbors = 30\n15:26:12 Initializing from normalized Laplacian + noise (using RSpectra)\n15:26:12 Commencing optimization for 500 epochs, with 66896 positive edges\n15:26:14 Optimization finished\n\nall_data_sub &lt;- RunUMAP(all_data_sub, reduction = \"integrated.rpca\", dims = 1:10, reduction.name = \"umap.rpca\")\n\n15:26:14 UMAP embedding parameters a = 0.9922 b = 1.112\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\nAlso defined by 'BiocGenerics'\n15:26:14 Read 1670 rows and found 10 numeric columns\n15:26:14 Using Annoy for neighbor search, n_neighbors = 30\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\nAlso defined by 'BiocGenerics'\n15:26:14 Building Annoy index with metric = cosine, n_trees = 50\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\n15:26:14 Writing NN index file to temp file /tmp/Rtmp7eCxNF/file1c38c817257154\n15:26:14 Searching Annoy index using 8 threads, search_k = 3000\n15:26:15 Annoy recall = 100%\n15:26:15 Commencing smooth kNN distance calibration using 8 threads with target n_neighbors = 30\n15:26:16 Initializing from normalized Laplacian + noise (using RSpectra)\n15:26:16 Commencing optimization for 500 epochs, with 66252 positive edges\n15:26:19 Optimization finished\n\nall_data_sub &lt;- RunUMAP(all_data_sub, reduction = \"harmony\", dims = 1:10, reduction.name = \"umap.harmony\")\n\n15:26:19 UMAP embedding parameters a = 0.9922 b = 1.112\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\nAlso defined by 'BiocGenerics'\n15:26:19 Read 1670 rows and found 10 numeric columns\n15:26:19 Using Annoy for neighbor search, n_neighbors = 30\nFound more than one class \"dist\" in cache; using the first, from namespace 'spam'\nAlso defined by 'BiocGenerics'\n15:26:19 Building Annoy index with metric = cosine, n_trees = 50\n0%   10   20   30   40   50   60   70   80   90   100%\n[----|----|----|----|----|----|----|----|----|----|\n**************************************************|\n15:26:19 Writing NN index file to temp file /tmp/Rtmp7eCxNF/file1c38c83a7ab4ab\n15:26:19 Searching Annoy index using 8 threads, search_k = 3000\n15:26:19 Annoy recall = 100%\n15:26:20 Commencing smooth kNN distance calibration using 8 threads with target n_neighbors = 30\n15:26:21 Initializing from normalized Laplacian + noise (using RSpectra)\n15:26:21 Commencing optimization for 500 epochs, with 66376 positive edges\n15:26:23 Optimization finished\n\n\n\np1 &lt;- DimPlot(\n  all_data_sub,\n  reduction = \"umap.unintegrated\",\n  group.by = \"cca_clusters\",\n  split.by = \"orig.ident\",  \n  combine = FALSE, label.size = 2\n)\n\np1\n\n[[1]]\n\n\n\n\n\n\np2 &lt;- DimPlot(\n  all_data_sub,\n  reduction = \"umap.rpca\",\n  group.by = \"rpca_clusters\",\n  split.by = \"orig.ident\",  \n  combine = FALSE, label.size = 2\n)\np2\n\n[[1]]\n\n\n\n\n\n\np3 &lt;- DimPlot(\n  all_data_sub,\n  reduction = \"umap.harmony\",\n  group.by = \"harmony_clusters\",\n  split.by = \"orig.ident\",  \n  combine = FALSE, label.size = 2\n)\np3\n\n[[1]]\n\n\n\n\n\n\np4 &lt;- DimPlot(\n  all_data_sub,\n  reduction = \"umap.cca\",\n  group.by = \"cca_clusters\",\n  split.by = \"orig.ident\",  \n  combine = FALSE, label.size = 2\n)\np4\n\n[[1]]\n\n\n\n\n\nYou can manually set the colors for the clusters, like this: First, get a list of all the built in colors that R knows about and use grep to remove anything with gray or grey or light in the color name.\n\ncolors &lt;- grDevices::colors()[grep('gr(a|e)y|light', grDevices::colors(), invert = T)]\n\nThen pick enough colors from that list so that each cca_cluster has its own color\n\ncca_cluster_colors &lt;- sample(x = colors, size = all_data_sub@meta.data$cca_clusters %&gt;% unique() %&gt;% length())\n\nAssign names so that each color is associated with a cluster identity:\n\nnames(cca_cluster_colors) &lt;-all_data_sub@meta.data$cca_clusters %&gt;% unique() \ncca_cluster_colors\n\n           1            6            5            0            2            3 \n \"seagreen3\"  \"seagreen2\"     \"coral1\"    \"orange1\" \"royalblue1\" \"olivedrab3\" \n           4            8            7 \n \"burlywood\"        \"red\"  \"seashell4\" \n\n\nWe can do the same and use the Zissou palette with hcl.colors (run hcl.pals() to see all options)\n\nzissou_colors &lt;- hcl.colors( all_data_sub@meta.data$cca_clusters %&gt;% unique() %&gt;% length(), \"Zissou 1\")\nnames(zissou_colors) &lt;-all_data_sub@meta.data$cca_clusters %&gt;% unique() \n\nWe can also generate new color palettes using RColorBrewer. You can see all of the color palettes available through RColorBrewer if you run display.brewer.all(). We specify that we want to use 8 colors from the ‘Set2’ palette from RColorBrewer, then we use colorRampPalette to expand that palette to make sure we have enough colors for all of the unique clusters.\n\nset2_colors &lt;- colorRampPalette(brewer.pal(8, 'Set2'))(all_data_sub@meta.data$cca_clusters %&gt;% unique() %&gt;% length())\n\nThen plot the cell using these color themes:\n\nDimPlot(\n  all_data_sub,\n  reduction = \"umap.cca\",\n  group.by = \"cca_clusters\",\n  combine = FALSE, label.size = 2,\n  cols = cca_cluster_colors\n)\n\n[[1]]\n\n\n\n\n\n\nDimPlot(\n  all_data_sub,\n  reduction = \"umap.cca\",\n  group.by = \"cca_clusters\",\n  combine = FALSE, label.size = 2,\n  cols = set2_colors\n)\n\n[[1]]\n\n\n\n\n\nWe can leave the legend off, use the Zissou colors, omit the split_by argument and the legend:\n\nzissou_plot &lt;- DimPlot(\n  all_data_sub,\n  reduction = \"umap.cca\",\n  group.by = \"cca_clusters\",\n  cols = zissou_colors\n) + NoLegend()\n\nThen we can label the clusters:\n\nLabelClusters(plot = zissou_plot , id = \"cca_clusters\", box = T, repel = T)\n\n\n\n\nOnce integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always re-split the layers in case you would like to re-perform integrative analysis.\n\nall_data_sub &lt;- JoinLayers(all_data_sub, assay ='RNA')"
  },
  {
    "objectID": "index.html#differential-expression-analysis",
    "href": "index.html#differential-expression-analysis",
    "title": "Introduction",
    "section": "0.14 Differential Expression Analysis",
    "text": "0.14 Differential Expression Analysis\nThe bulk of Seurat’s differential expression features can be accessed through the FindMarkers() function. By default, Seurat performs differential expression (DE) testing based on the non-parametric Wilcoxon rank sum test. To test for DE genes between two specific groups of cells, specify the ident.1 and ident.2 parameters. Since we normalized using SCTransform, we have to run PrepSCTFindMarkers() first. Given a merged object with multiple SCT models, this function uses minimum of the median UMI (calculated using the raw UMI counts) of individual objects to reverse the individual SCT regression model using minimum of median UMI as the sequencing depth covariate. The counts slot of the SCT assay is replaced with recorrected counts and the data slot is replaced with log1p of recorrected counts. Then set the DefaultAssay to be the RNA assay.\n\nIdents(all_data_sub) &lt;- \"orig.ident\"\nall_data_sub &lt;- PrepSCTFindMarkers(all_data_sub)\n\nFound 3 SCT models. Recorrecting SCT counts using minimum median counts: 1669\n\nDefaultAssay(all_data_sub) &lt;- \"RNA\"\n\nstim_vs_ctrl &lt;- FindMarkers(all_data_sub, ident.1 = \"IMMUNE_STIM\", ident.2 = \"IMMUNE_CTRL\")\nhead(stim_vs_ctrl %&gt;% dplyr::filter(p_val_adj &lt; .05 & avg_log2FC &gt; 1))\n\n              p_val avg_log2FC pct.1 pct.2     p_val_adj\nIFIT3 2.006122e-220   45.89104 0.930 0.053 2.999754e-216\nIFIT1 3.150672e-219   36.27346 0.919 0.036 4.711200e-215\nISG15 1.977188e-217  373.63183 0.993 0.311 2.956489e-213\nISG20 3.828587e-208  105.31635 0.987 0.411 5.724886e-204\nIFI6  2.455061e-202   33.05172 0.949 0.179 3.671053e-198\nMX1   1.702260e-190   31.79925 0.890 0.093 2.545389e-186\n\n\nThe results data frame has the following columns :\np_val : p-value (unadjusted)\navg_log2FC : log fold-change of the average expression between the two groups. Positive values indicate that the feature is more highly expressed in the first group.\npct.1 : The percentage of cells where the feature is detected in the first group\npct.2 : The percentage of cells where the feature is detected in the second group\np_val_adj : Adjusted p-value, based on Bonferroni correction using all features in the dataset.\nIf the ident.2 argument is omitted, FindMarkers will test for differentially expressed features between the group specified by ident.1 and all other cells. Additionally, the parameter only.pos can be set to TRUE to only search for positive markers, i.e. features that are more highly expressed in the ident.1 group.\n\nstim_vs_all &lt;- FindMarkers(all_data_sub, ident.1 = \"IMMUNE_STIM\", only.pos = T)\nhead(stim_vs_all %&gt;% dplyr::filter(p_val_adj &lt; .05 & avg_log2FC &gt; 1))\n\n              p_val avg_log2FC pct.1 pct.2     p_val_adj\nIFIT3 2.551659e-271  46.113078 0.930 0.068 3.815496e-267\nIFIT1 3.008184e-268  36.743585 0.919 0.055 4.498138e-264\nISG15 3.449725e-253 374.102461 0.993 0.357 5.158374e-249\nISG20 1.243457e-246  97.127625 0.987 0.426 1.859342e-242\nIFI6  5.973017e-223   3.365912 0.949 0.241 8.931453e-219\nIFIT2 5.133239e-207  49.704325 0.763 0.038 7.675733e-203\n\n\nWe can switch idents to find marker genes for the clusters:\n\nIdents(all_data_sub) &lt;- 'cca_clusters'\n\nUse FindAllMarkers to compare each cluster to all the other clusters. For the sake of speed, we are selecting only positive genes that are expressed in at least 90% of the cells for a given cluster:\n\ncca_markers &lt;- FindAllMarkers(all_data_sub, min.pct = .90, only.pos=TRUE)\n\nCalculating cluster 0\n\n\nCalculating cluster 1\n\n\nCalculating cluster 2\n\n\nCalculating cluster 3\n\n\nCalculating cluster 4\n\n\nCalculating cluster 5\n\n\nCalculating cluster 6\n\n\nCalculating cluster 7\n\n\nCalculating cluster 8\n\n\nLook at the marker genes with the biggest fold change per cluster\n\ntop_cluster_markers &lt;- \n  cca_markers %&gt;% \n  group_by(cluster) %&gt;%\n  dplyr::filter(p_val_adj &lt;= 1e-100) %&gt;%\n  dplyr::filter(avg_log2FC &gt; 1) %&gt;% \n  dplyr::filter(pct.1 &gt; .9) %&gt;%\n  slice_max(n = 2, order_by = abs(avg_log2FC))\ntop_cluster_markers\n\n# A tibble: 5 × 7\n# Groups:   cluster [3]\n      p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene  \n      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt; \n1 2.87e-198     186.   1     0.908 4.30e-194 0       FTL   \n2 6.20e-113      89.2  0.988 0.61  9.27e-109 0       SAT1  \n3 1.02e-145      35.8  0.979 0.159 1.52e-141 4       FCGR3A\n4 8.36e-118      22.8  0.938 0.178 1.25e-113 4       MS4A7 \n5 1.38e-106       9.39 0.962 0.036 2.06e-102 8       NME1  \n\n\nMake a FeaturePlot to look at the expression of one of the cluster markers. It will plot the data slot from the default assay. We can switch the default assay to SCT first and specify that we want to use the data slot (log1p(counts)):\n\nDefaultAssay(all_data_sub) &lt;- \"SCT\"\n\nFeaturePlot(all_data_sub, features = c(\"CCL3\"), reduction = 'umap.cca', order = T, slot = 'data')\n\n\n\n\nWe can adjust the default colors and use one of the viridis palettes:\n\nFeaturePlot(all_data_sub, features = c(\"CCL3\"), reduction = 'umap.cca', order = T, slot = 'data') & ggplot2::scale_color_gradientn(colors = viridis::turbo(n = 10, direction = 1))\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\nWe can add the cluster labels:\n\nFeaturePlot(all_data_sub, features = c(\"CCL3\"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = viridis::turbo(n = 10, direction = 1))\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\nWe can use RColorBrewer palettes instead and specify that we want to drop the colors on the extreme ends of the Spectral palette:\n\nFeaturePlot(all_data_sub, features = c(\"CCL3\"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8])\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\nAnd add a legend title\n\nFeaturePlot(all_data_sub, features = c(\"CCL3\"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8]) & ggplot2::labs(color = \"log1p\\n(counts)\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\n\n\n\nWe can also make a heatmap of the cluster markers. Seurat heatmaps use the scale.data slot by default.\n\nDoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene)\n\n\n\n\nWe can customize this heatmap as well:\n\nDoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() \n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\nWe can adjust which legends are shown, like this:\n\nDoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() & ggplot2::guides(fill=FALSE)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\nOr like this:\n\nDoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() & ggplot2::guides(colour=FALSE)\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\nAnother helpful visualization from Seurat is DotPlot. The size of each dot indicates the percentage of cells expressing the feature and the color is the average expression level. It uses the scale.data slot by default.\n\nDotPlot(all_data_sub, features = top_cluster_markers$gene) \n\n\n\n\nWe can use more custom colors:\n\nDotPlot(all_data_sub, features = top_cluster_markers$gene) & \n    viridis::scale_color_viridis(option = \"magma\", direction = -1) \n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale."
  }
]