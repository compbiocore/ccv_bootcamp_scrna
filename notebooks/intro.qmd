---
title: "Introduction"
format: html
editor: visual
execute: 
  cache: true
---

## To use this notebook

1.  Go to ood.ccv.brown.edu (you will need an Oscar account).
2.  Go to 'Clusters' in the blue menu bar at the top and click the drop-down that says '\>\_OSCAR Shell Access'
3.  Go to your home folder and make a folder called `scrna_r_workshop_2023` (`cd ~` and `mkdir scrna_r_workshop_2023`), then type `pwd` to get the path to this folder.
4.  Look under `Interactive Apps` in the blue menu bar and click on `RStudio on Singularity` under `Expert GUIs`.

Fill in the fields as follows:

-   `Account`: leave blank\
-   `Partition`: leave blank\
-   `Number of hours`: 3\
-   `Num Cores`: 8\
-   `Memory`: 90\
-   `Singularity Container Path`:/gpfs/data/shared/databases/workshops/bootcamp_2023/scrna_r_workshop.sif\
-   `Package install Path`: leave blank\
-   `Path for R Executable`: This should be the full path to the `scrna_r_workshop_2023` you made in step 3.\
-   `R Module`: leave blank\
-   `Additional Data Path`: /gpfs/data/shared/databases/workshops/bootcamp_2023/scrna_r_workshop\

Once your job starts, click the button to connect to session.\
At the top of the screen you'll see a menu bar that starts with 'file', click on 'file' and 'open file'.\
It will ask for a File name -- paste this into the box: `/gpfs/data/shared/databases/workshops/bootcamp_2023/scrna_r_workshop/intro.Rmd`

## Introduction to scRNA-seq

**What we will cover**\
- How does scRNA-seq differ from bulk RNA-seq?\
- scRNAseq technologies\
- Parallelization options for Seurat and other packages\
- Seurat objects and importing data\
- Data merging, QC, and filtering\
- SCTransform normalization, clustering, dimension reduction\
- Data integrationÂ  - Differential expression testing\
- Data visualization\
- Classifying cell types with a reference atlas with TransferAnchors from Seurat\

Much of this notebook is adapted from the Seurat vignettes https://satijalab.org/seurat and GitHub repository https://github.com/satijalab/seurat

## How does scRNA-seq differ from bulk RNA-seq?

![bulk vs single cell](image/bulk_vs_singlecell.png)

-   In bulk RNA-seq you are taking a snapshot of expression of all the cells in a sample and your measurements are aggregated across all of those cells.

-   In scRNA-seq, you can get a sense of the heterogeneity of the cells in your sample.

    -   Are there novel or rare cell types?

    -   What about cell type specific gene expression?

    -   Does the distribution of different cell types change across time or treatment?

-   This increased resolution comes with some unique challenges.

    -   Dropouts - genes that are not detected in some cells, can lead to sparse expression matrices with many zero values.

    -   Doublets - sequencing two cells at the same time and can't distinguish their expression or cell types, need to filter these out during QC.

    -   Dying cells - you will lose some cells because they are dead or dying, you can also filter these out during sample QC.

    -   You also should be cautious when thinking about your sample sizes. For example, you may be sequencing thousands of cells but if they all come from the same mouse you lose the ability to generalize your findings.

## scRNAseq technologies

-   Although 10X genomics is probably the most popular technology for scRNA-seq, there are other flavors as well (see PMID 30472192 and PMID 28212749).

![](image/10x_flow.png)

10x sequencing encapsulates a cell, reagents, and a bead w/ primer in an oil droplet (aka GEM or Gel Bead-in EMulsion). Again, if you have a situation where one droplet has two cells, this is a 'doublet', you can also have empty droplets where there's no cell encapsulated.

![](image/10x_bead.png)

After encapsulation of cells, beads, and reagents in the oil droplets, the bead is dissolved and releases primers. The poly (dT) primers are used for generating the gene expression libraries. The capture sequence primers are shown in a lighter shading because they are only used in situations where you'd like to add an extra channel of information to your experiment by using feature barcoding (cell-surface protein characterization, multiplexing, etc.).

## Library preparation details

Let's go over the details of how the library prep works (see https://teichlab.github.io/scg_lib_structs/methods_html/10xChromium3.html)

![sc bead](image/seq_step1.png)The polyA mRNAs are captured using the oligo(dT) on the beads, MMLV (Moloney Murine Leukemia Virus) reverse transcriptase synthesizes complementary strand to the fragment thats captured.\\\\

![](image/seq_step2.png)

The RT adds some extra Cs on the end.\\\\

![](image/seq_step3.png)

The template-switching oligo is added so we can continue across the other strand.\\\\

![sc bead](image/seq_step4.png) Add primers to amplify full length cDNA\\\\

![sc bead](image/seq_step5.png) Fragment cDNA, perform A-tailing\\\\

![sc bead](image/seq_step6.png) At this point we add the Truseq adapters, product 3 is what you'll actually sequence.\\\\

![](image/seq_step7.png)

Add the library PCR primers 1 and 2 to amplify the library\\\\

![sc bead](image/seq_step8.png)The final library structure looks like the above image -- the exact length of the UMI might depend on which chemistry you're using.

![sc bead](image/10x_lib_seq.png)The actual sequencing looks like the above image. Truseq Read 1 uses bottom strand as template and sequences the bacrode + UMI. Sample Index primer sequences the sample index using bottom strand as template. Regenerate clusters and Truseq Read 2 primer sequences the second read using the top strand as template.\\\\

![](image/single_vs_double.png)

The above steps assume a single index library, if you're using dual indexes there will be another sample index between the P5 and Truseq Read 1. Dual indexed libraries are beneficial to help prevent index hopping (https://www.10xgenomics.com/blog/sequence-with-confidence-understand-index-hopping-and-how-to-resolve-it).\\\\

```         
::: {.callout-tip}
## Tip 
https://teichlab.github.io/scg_lib_structs/ is an excellent resource for information about the resulting library structures for 10x libraries (and other single cell technologies like Drop-seq or SMART-seq) and was our resource for most of this section.
:::
```

## Parallelization options for Seurat and other packages

Let's get started. First, we can set the `.libPaths()`, which essentially tells R that it should look for packages inside these locations inside the Singularity container.

```{r echo=FALSE, message=FALSE}
.libPaths(c('/usr/local/lib/R/site-library', '/usr/local/lib/R/library'))
```

All of the methods we are discussing here involve computationally heavy methods, and as such also take advantage of parallelization where they can. Often in their documentation you will find how to use multiple cores when calling a function, usually involving a provided argument or involving a package called `future`.

For example, Seurat has a [vignette on parallelization](https://satijalab.org/seurat/archive/v4.3/future_vignette) with `future`. We will follow it here:

```{r}
library(future)
# check the current active plan
plan()
```

`plan()` says that we are currently set up to run code *sequentially* or non-parallelized. To see more information, run this code chunk:

```{r}
?future::plan
```

Now, we set workers=8 because we've requested 8 cores. Additionally, we set `multisession` instead of `multiprocess` despite what the vignette says, because `multiprocess` is actually deprecated in `future` and we should be explicitly specifying `multisession` or `multicore` instead. Getting into the difference is out of scope of this workshop, but you can [read more](https://cran.r-project.org/web/packages/future/vignettes/future-1-overview.html) on future yourself if interested.

```{r}
# change the current plan to access parallelization
plan("multisession", workers = 8)
plan()
```

We'll also set a seed at the start of the notebook so that we can reproduce our results if we decide to re-run this notebook at some future date. We also set `future.globals.maxSize`, see the Seurat future vignette linked above for discussion about why we do this (basically we might be exceeding the allowed global variable size so we make that default bigger).

```{r}
set.seed(61)
options(future.globals.maxSize = 4000 * 1024^2)
```


## Seurat objects overview

::: callout-important
In November of 2023, Seurat made a major upgrade to Seurat v5 (https://github.com/satijalab/seurat/releases), which included many new functions and other changes (https://satijalab.org/seurat/articles/announcements.html#changes-in-seurat-v5), including some very big changes to the default behavior of Seurat. **You will likely see different results depending on which version of Seurat you have used for your analysis.** Feel free to come to our office hours if you want help setting up reproducible analyses using either version of Seurat.
:::

This workshop focuses on using Seurat objects to structure your scRNA-seq data (https://github.com/satijalab/seurat/wiki/Seurat), we will attempt to cover how to interact with Seurat objects in Seurat v4 and v5, but won't exhaustively cover the differences between the two versions.

Here's a schematic of a Seurat object:

![Schematic of a Seurat object](image/seurat_object.png){width="470" height="400"}

-   Each Seurat object is composed of different components:
    -   **`assays`** is a list of all the assays in the object.
        -   Defaults to `RNA` assay, but you can add others (like `SCT` for normalizd counts, shown in the figure above, could also be antibody-derived tags, etc.).

        -   You can see all assays using `Assays(ifnb)`, see which assay is the currently active assay by looking in the `active.assay` slot (`ifnb@active.assay`) and switch between them using the `DefaultAssay()` function (`DefaultAssay(ifnb) <- 'RNA'`).

        -   Each assay will store multiple transformations of the data in different `slots` (or `layers` in Seurat v5) -- in the case of `RNA` data these slots are:

            -   `@counts` contains the raw counts.
            -   `@data` contains the normalized counts.
            -   `@scale.data` contains the scaled data for dimensional reduction.

        -   The `slots` (Seurat v4) or `layers` (Seurat v5) store the data as a sparse matrix where the rows are gene and the columns are cells.

        -   In Seurat v4, you could access the raw counts like this:`GetAssayData(ifnb, assay="RNA", slot='counts')`. This will still work in Seurat v5, but you'll get a warning message. In Seurat v5 it is intended that you access the counts using the `LayerData` function, like this: `LayerData(ifnb, assay='RNA', layer='counts')`

        -   In either version of Seurat `ifnb[['RNA']]$counts` will also work.
    -   **`meta.data`** is a matrix of all the cell-level metadata.
        -   This will include information about which condition, timepoint, batch, etc. a for a given cell.
        -   It also includes metrics that will be relevant for QC, like `nCount_RNA` and `nFeature_RNA`
            -   `nCount_RNA` is the total number of molecules (UMIs) detected within a cell.
            -   `nFeature_RNA` is the total number of genes detected within a cell.
        -   Once you have completed clustering, you'll also see information about which cluster each cell has been assigned to.
        -   The different categories or columns in the `meta.data` are also called `Idents` in Seurat.
        -   You can see the current `Ident` in the `active.ident` slot (`ifnb@active.ident`) and switch between them using the `Idents()` function (this will probably be important for running differential expression testing).
        -   You can use `table(Idents(ifnb))` for a quick summary of the number of cells in each grouping.
    -   **`graphs`** is a list of the nearest neighbor graphs.
        -   The objects stored in `graphs` are cell x cell matrices containing the neighborhood overlap (Jaccard index) between every cell and its nearest neighbors.
    -   **`reductions`** is a list of `DimReduc` objects.
    -   **`version`** contains information about which version of Seurat was used to make the object.
    -   There are other optional slots, including **`tools`** and **`misc`** that can be populated by specific analysis tools (`tools`) or users can store their own additional information (`misc`).

## Importing data and interacting with Seurat objects

**Much of this notebook is taken from the various Seurat vignettes: https://satijalab.org/seurat/articles/get_started.html**

First, load all the libraries we need, including some Seurat data packages. The last line will update the Seurat objects so that they are compatible with the newest version of Seurat.

```{r message=FALSE, warning=FALSE}
.libPaths(c('/usr/local/lib/R/site-library', '/usr/local/lib/R/library'))

library(RColorBrewer)
library(Seurat)
library(patchwork)
#library(ggplot2)
library(dplyr)
library(hdf5r)
library(stringr)
library(biomaRt)
#library(viridis)
#library(SeuratDisk)
library(SeuratData)
#library(msigdbr)
#library('pbmc3k.SeuratData')
#library('cbmc.SeuratData')
library('ifnb.SeuratData')
#data("pbmc3k")
#data("cbmc")
data("ifnb")
ifnb <- UpdateSeuratObject(ifnb)
data("pbmc3k")
pbmc3k <- UpdateSeuratObject(pbmc3k)
```

-   We are using the `SeuratData` package for some test data.
-   Use `AvailableData()` to see what datasets are available

```{r}
SeuratData::AvailableData() %>% data.frame() %>% head()
SeuratData::AvailableData() %>% data.frame() %>% dplyr::filter(Installed == 'TRUE')
```

-   We've already installed some test data in this container. You would usually be able to install more data sets using `InstallData` but won't have permissions to install in this container.
-   It is more likely that you are using Seurat with your own data -- you can use the functions `Read10X` or `Read10X_h5` to import data.
-   `Read10X_h5` works with H5 files -- "Hierarchical Data Format (HDF5 or H5). H5 is a binary format that can compress and access data much more efficiently than text formats such as MEX, which is especially useful when dealing with large datasets." https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/h5_matrices.
-   You can also use `Read10X` and give a path to a folder that contains your matrix, features, and barcode tsv files.
-   After you have read in the 10X data, use it as the input to the `CreateSeuratObject` function.

As an aside, you can also import counts matrix data from GEO using something like this function I wrote based on a biostars post (although I make no guarantees that this will work with everything from GEO -- proceed with caution and feel free to come by office hours for help if this is something you need to do):

```{r, eval=FALSE}
#https://www.biostars.org/p/9527335/#9527339
counts_to_seurat <- function(matrix_path, project){
  
  #use fread to import the data
  mat <- data.table::fread(matrix_path)

  #set rownames to be the first column of gene IDs
  rownames(mat) <- mat$V1 
  
  #make `mat` be only numeric data by removing column of gene IDs
  mat$V1 <- NULL

  #create Seurat object
  seu <- CreateSeuratObject(counts = mat, 
                            project = project)
  
  return(seu)
}

E12_JS_14 <- counts_to_seurat(matrix_path = '/data/cbc/Dennery_scRNAseq/dennery_2023_grant/GSE165063/GSM5025543_E12_JS-14_processed_counts.csv', project = 'E12_JS_14')
```

We can look at the Seurat object we've loaded from SeuratData:

```{r}
?ifnb
```
The `ifnb` dataset is 14,000 IFNB-Stimulated and Control PBMCs (peripheral blood mononuclear cells). 

```{r}
ifnb
```
We can also see that Seurat v5 assays store data in layers. These layers can store raw, un-normalized counts (layer='counts'), normalized data (layer='data') or z-scored/variance-stabilized data (layer='scale.data'). What assays and meta.data are available?

```{r}
ifnb@assays
head(ifnb@meta.data)
```
We have an `RNA` assay, information about which experimental condition the cell came from (`orig.ident` and `stim`), the number of genes (`nFeature_RNA`) and molecules (`nCount_RNA`) in each cell. This particular object also comes pre-annotated (`seurat_annotations`). 

We will aim to eventually integrate the different samples (`IMMUNE_CTRL` and `IMMUNE_STIM` from `orig.ident`) together. In previous versions of Seurat, we would require the data to be represented as a list of different Seurat objects. When using Seurat v5 assays, we can instead keep all the data in one object, but simply split the layers.

```{r}
ifnb[["RNA"]] <- split(ifnb[["RNA"]], f = ifnb$orig.ident)
ifnb
```

After splitting, there are now 4 layers (a counts and data layer for each batch). Since the data is split into layers, normalization and variable feature identification is performed for each sample independently (a consensus set of variable features is automatically identified).


## Data merging

In addition to `ifnb`, we have also installed `pbmc3k`, which is from 2,700 peripheral blood mononuclear cells (PBMC) from 10X genomics. 

```{r}
?pbmc3k
pbmc3k@assays
head(pbmc3k@meta.data)
```

- First, lets subset our datasets so they are smaller and easier to work with for this workshop.

```{r}
pbmc3k <- subset(pbmc3k, downsample = 300)
ifnb <- subset(ifnb, downsample = 700)

```

- Let's merge the datasets to make our QC and filtering a bit smoother.
- `merge()` merges the raw count matrices of two Seurat objects and creates a new Seurat object with the resulting combined raw count matrix. 
- To easily tell which original object any particular cell came from, you can set the `add.cell.ids` parameter with an c(x, y) vector, which will prepend the given identifier to the beginning of each cell name. 
- The original project ID will remain stored in object meta data under `orig.ident`.

```{r}

all_data <- merge(x = ifnb, y = pbmc3k, add.cell.ids = c("ifnb", "pbmc3k"), project = 'pbmc')

```

## Data QC

- We care about the percentage of reads that map to the mitochondrial genome because high mitochondrial reads in a cell can indicate that the cells are low-quality or dying cells
- The mitochondrial QC metrics are calcualted with the `PercentageFeatureSet()` function, which calculates the percentage of counts originating from a set of features
- We use the set of all genes starting with MT- as a set of mitochondrial genes -- the format of the mt sequences will vary depending on which organism/genome is used...(might be 'mt-' for example).

```{r "Figure out format of MT gene IDs"}
rownames(all_data) %>% grep(pattern = '^mt-', ignore.case = TRUE, value = TRUE)
```

```{r "add mt percent data"}
all_data[["percent.mt"]] <- PercentageFeatureSet(all_data, pattern = "^MT-")
```

- Before we plot, we can set the order of the object idents to whatever order we'd like:
```{r}
Idents(all_data) <- 'orig.ident'
levels(all_data) <- c("pbmc3k", "IMMUNE_CTRL", "IMMUNE_STIM")
```

- We can also look at plots showing the distribution of the `percent.mt`, `nFeature_RNA` and `nCount_RNA`
- `nFeature_RNA` is the number of genes 
- `nCount_RNA` is the number of UMIs (unique molecules -- like counts)

```{r}
VlnPlot(all_data, features = "nFeature_RNA")
```
```{r}
VlnPlot(all_data, features = "nCount_RNA")
```
```{r}
VlnPlot(all_data, features="percent.mt")
```

```{r}
FeatureScatter(all_data, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
```
```{r}
FeatureScatter(all_data, feature1 = "nCount_RNA", feature2 = "percent.mt")
```
```{r}
FeatureScatter(all_data, feature1 = "nFeature_RNA", feature2 = "percent.mt")
```

You can also just use ggplot to make your own custom visualizations of the information in the metadata. We make a separate matrix called `qc_data` and sorting it based on the `percent.mt` column. Then we make our own ggplot and specify that the x and y axes should be `nCount_RNA` and `nFeature_RNA` and that the points should be colored based on `percent.mt`. Then, use `scale_color_gradientn` to specify how the points should be colored, specifying that the limit should be between 0 and 10 and that we should `squish` anything that is out of bounds (effectively making our limits 0 and >10).
```{r}

qc_data <- all_data@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %>% arrange(percent.mt)

ggplot2::ggplot(qc_data, ggplot2::aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + 
  ggplot2::geom_point() + 
 ggplot2:: scale_color_gradientn(colors = rev(brewer.pal(5, "Spectral")), limits = c(0,10), oob = (scales::squish)) +
  ggplot2::facet_wrap(~orig.ident) + 
  ggplot2::theme_bw()

```

- Low quality cells or empty droplets might have very few genes (`nFeatures`)
- Dead or dying cells will also have high mitochondrial reads (`percent.mt`)
- Doublets or multiplets will have high gene counts (`nFeatures`)
- The total number of molecules (`nCount`) detected in a cell corresponds with the number of genes (`nFeatures`)
- Most of the cells have less than 2000 genes and less than 7000 or so UMIs.
- Very low mitochondrial counts from the `ifnb` data and the nFeature_RNA scatter plots look strange -- perhaps this dataset was pre-filtered before being packaged into SeuratData.
- In the `pbmc3k` data, we can see groups of cells with high mitochondrial counts, low UMI counts, and lower numbers of genes.
- Our goal in QC filtering is to retain as much useful information as we can, while removing doublets, empty droplets, and dead cells.
- We will pick some thresholds for filtering based off of what we see in our data, keeping in mind that if you are doing this with your own data, your plots will probably look a bit different.

## Data Filtering

- Let's filter our data using `subset`, we'll keep cells that have between 500 and 7000 nFeature_RNA (genes) and less than 5% mitochondrial reads.

```{r}
all_data_sub <- subset(all_data, subset = nFeature_RNA > 500 & nFeature_RNA < 7000 & percent.mt < 5)
```

- You can re-examine your QC plots after filtering if you'd like:
```{r}
qc_data_sub <- all_data_sub@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %>% arrange(percent.mt)

ggplot2::ggplot(qc_data_sub,ggplot2:: aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + 
  ggplot2::geom_point() + 
  ggplot2::scale_color_gradientn(colors = rev(brewer.pal(5, "Spectral")), limits = c(0,10), oob = (scales::squish)) +
  ggplot2::facet_wrap(~orig.ident) + 
  ggplot2::theme_bw()
```

- We can also take a look at how many cells we lost from filtering (245 cells lost from `pbmc3k`).
```{r}
table(all_data@meta.data$orig.ident)
table(all_data_sub@meta.data$orig.ident)

```


## Normalization

### Theory

scRNAseq data is normalized so that we can mitigate technical effects while preserving the biological signal in the data -- we should be able to find the biological signal in cells irrespective of how deeply we sequenced the cell. The theory behind SCTransform (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) is very similar to the generalized linear models (GLMs) used in bulk RNAseq analysis packages like DESeq2 and edgeR. In DESeq2 a negative binomial model is fitted to the counts and the mean and dispersion (roughly speaking how variable the observed count will be from the mean count) estimates from that model are used as the test statistics for comparison between groups. The same idea applies with SCTransform, with an additional aspect where SCTransform pools information across genes with similar abundances in order to address the higher sparsity of single cell data.

Below is a side-by-side comparison of sctransform with NormalizeData, FindVariableFeatures and ScaleData on the PBMC3k data:

![sct](image/sctransform_vs_regular.png)

We also like this figure from the SCTransform paper, which shows how SCTransform ('Pearson Residuals') and the standard log-transformation approach ('Log-normalization') helps alleviate variance in your data from sequencing depth alone :

![sct_fig6](image/sct_fig6.png)

### When should you not use SCTransform?

The paper states:

`As our workflow leverages all genes (or a random sub-set) for the initial regularization, we make an implicit assumption that the majority of genes in the dataset do not exhibit significant biological variation...this assumption may be overly simplistic when performing scRNA-seq on a highly heterogeneous sample, we did not observe adverse affects when applying our model to human PBMC data, or any of the other datasets we examined.`

SCTransform might not work well if your data is highly heterogeneous and you expect that a high proportion of genes will exhibit significant biological variation across your samples. In this case, we would recommend the more standard workflow of `NormalizeData`, `FindVariableFeatures`, and `ScaleData`. 

### SCTransform versions

Seurat v5 runs SCTransform v2 (https://satijalab.org/seurat/archive/v4.3/sctransform_v2_vignette) by default, while Seurat v4 runs SCTransform v1 by default. SCTransform v2 "improves speed and memory consumption, the stability of parameter estimates, the identification of variable features, and the the ability to perform downstream differential expression analyses." This means you might get different results if you run Seurat v5 and re-normalize data that you have previously processed with Seurat v4. If you want to change from the default veresion of SCTransform, you can add the argument `vst.flavor = "v1"` (or  `vst.flavor = "v2"`))

### Running SCTransform

We will normalize using SCTransform and you might get see a warning that says 'iteration limit reached' when you run the function. This warning can be ignored (https://github.com/satijalab/sctransform/issues/25) because the parameter estimation generating this warning is regularized later anyway. You can use the `vars.to.regress` argument to regress out nuisance variables (like cell cycle, batch effects, or `percent.mt`). By default SCTransform will only return data for variable genes in the scale data slot -- adding the `return.only.var.genes = FALSE` argument to the function call to turn this option off (https://github.com/satijalab/seurat/issues/3553). In previous versions of Seurat, you would have to split your object into a list of Seurat objects based on the `orig.ident` and then run `SCTransform` on the list, which is not necessary in Seurat v5.



```{r "SCTransform"}

start.time <- Sys.time()
all_data_sub <- SCTransform(all_data_sub, vars.to.regress = "percent.mt", verbose = FALSE, return.only.var.genes = FALSE)
end.time <- Sys.time()
end.time - start.time
  
```

Then run PCA

```{r}
all_data_sub <- RunPCA(all_data_sub)
```

We can make an elbow plot:

```{r}
ElbowPlot(all_data_sub)
```

Based on this plot, we get diminishing information returned once we get above \~10-15 PCs. We will use this information when we run clustering.

## Integration

Integration of single-cell sequencing datasets, for example across experimental batches, donors, or conditions, is often an important step in scRNA-seq workflows. Integrative analysis can help to match shared cell types and states across datasets, which can boost statistical power, and most importantly, facilitate accurate comparative analysis across datasets. In previous versions of Seurat we introduced methods for integrative analysis, including our âanchor-basedâ integration workflow. Many labs have also published powerful and pioneering methods, including Harmony and scVI, for integrative analysis. We recognize that while the goal of matching shared cell types across datasets may be important for many problems, users may also be concerned about which method to use, or that integration could result in a loss of biological resolution. In Seurat v5, we introduce more flexible and streamlined infrastructure to run different integration algorithms with a single line of code. This makes it easier to explore the results of different integration methods, and to compare these results to a workflow that excludes integration steps. 

Seurat v5 enables streamlined integrative analysis using the `IntegrateLayers` function. The method currently supports five integration methods. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches (samples):

```         
Anchor-based CCA integration (method=CCAIntegration)
Anchor-based RPCA integration (method=RPCAIntegration)
Harmony (method=HarmonyIntegration)
FastMNN (method= FastMNNIntegration)
scVI (method=scVIIntegration)
```

A detailed discussion of these different methods is outside the scope of this workshop, but you can find more detail on each method in Seuratâs documentation. However, the Seurat authors state:

By identifying shared sources of variation between datasets, CCA is well-suited for identifying anchors when cell types are conserved, but there are very substantial differences in gene expression across experiments. CCA-based integration therefore enables integrative analysis when experimental conditions or disease states introduce very strong expression shifts, or when integrating datasets across modalities and species. However, CCA-based integration may also lead to overcorrection, especially when a large proportion of cells are non-overlapping across datasets. RPCA-based integration runs faster, and also represents a more conservative approach where cells in different biological states are less likely to âalignâ after integration. We therefore recommend RPCA during integrative analysis where:

-   A substantial fraction of cells in one dataset have no matching type in the other
-   Datasets originate from the same platform (i.e. multiple lanes of 10x genomics)
-   There are a large number of datasets or cells to integrate (see here for more tips on integrating large datasets)

There are also papers that attempt to benchmark different integration approaches:

"For example, the use of Harmony is appropriate for simple integration tasks with distinct batch and biological structure; however, this method typically ranks outside the top three when used for complex real data scenarios... Methods that used cell annotations to integrate batches (scGen and scANVI) performed well across tasks...Particularly in more complex integration tasks, we observed a tradeoff between batch effect removal and bio-conservation (Fig. 3a and Supplementary Data 1). While methods such as SAUCIE, LIGER, BBKNN and Seurat v3 tend to favor the removal of batch effects over conservation of biological variation, DESC and Conos make the opposite choice, and Scanorama, scVI and FastMNN (gene) balance these two objectives. Other methods strike different balances per task (Extended Data Fig. 4). This tradeoff is particularly noticeable where biological and batch effects overlap. For example, in the lung task, three datasets sample two distinct spatial locations (airway and parenchyma). Particular cell types such as endothelial cells perform different functions in these locations (for example, gas exchange in the parenchyma)."
(Luecken et al 2022 https://doi.org/10.1038/s41592-021-01336-8).

We will run `CCAIntegration` (this was the default flavor of integration in previous versions of Seurat), `RPCAIntegration`, and `HarmonyIntegration`. Note that we are specifying that we used `SCT` normalization:

```{r}
all_data_sub<- IntegrateLayers(
  object = all_data_sub, method = CCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.cca", normalization.method = "SCT",
  verbose = FALSE
)
```

```{r}
all_data_sub <- IntegrateLayers(
  object = all_data_sub, method = RPCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.rpca", normalization.method = "SCT",
  verbose = FALSE
)
```

```{r}
all_data_sub <- IntegrateLayers(
  object = all_data_sub, method = HarmonyIntegration,
  orig.reduction = "pca", new.reduction = "harmony", normalization.method = "SCT",
  verbose = FALSE
)
```

Seurat will cluster your cells into groups of cells with similar expression patterns. The first step is `FindNeighbors`, which will construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). To cluster the cells, we run `FindClusters` to apply the Louvain algorithm to iteratively group cells together, with the goal of optimizing the standard modularity function. `FindClusters` takes a `resolution` argument (defaults to a value of 0.8), which sets the granularity of the clustering, setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells but the resolution might increase for larger datasets. Use a value above 1 if you want a larger number of communities (clusters), and a value below 1 if you want a smaller number of communities.

```{r}
all_data_sub <- FindNeighbors(all_data_sub, reduction = "integrated.cca", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "cca_clusters")

all_data_sub <- FindNeighbors(all_data_sub, reduction = "integrated.rpca", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "rpca_clusters")

all_data_sub <- FindNeighbors(all_data_sub, reduction = "harmony", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "harmony_clusters")

```

Run UMAP (Uniform Manifold Approximation and Projection) dimensional reduction technique on the unintegrated data and the different integration methods:

```{r}
all_data_sub <- RunUMAP(all_data_sub, dims = 1:10, reduction = "pca", reduction.name = "umap.unintegrated")

all_data_sub <- RunUMAP(all_data_sub, reduction = "integrated.cca", dims = 1:10, reduction.name = "umap.cca")
all_data_sub <- RunUMAP(all_data_sub, reduction = "integrated.rpca", dims = 1:10, reduction.name = "umap.rpca")
all_data_sub <- RunUMAP(all_data_sub, reduction = "harmony", dims = 1:10, reduction.name = "umap.harmony")
```



```{r}
p1 <- DimPlot(
  all_data_sub,
  reduction = "umap.unintegrated",
  group.by = "cca_clusters",
  split.by = "orig.ident",  
  combine = FALSE, label.size = 2
)

p1
```

```{r}
p2 <- DimPlot(
  all_data_sub,
  reduction = "umap.rpca",
  group.by = "rpca_clusters",
  split.by = "orig.ident",  
  combine = FALSE, label.size = 2
)
p2
```

```{r}
p3 <- DimPlot(
  all_data_sub,
  reduction = "umap.harmony",
  group.by = "harmony_clusters",
  split.by = "orig.ident",  
  combine = FALSE, label.size = 2
)
p3
```

```{r}
p4 <- DimPlot(
  all_data_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  split.by = "orig.ident",  
  combine = FALSE, label.size = 2
)
p4
```

You can manually set the colors for the clusters, like this: First, get a list of all the built in colors that R knows about and use `grep` to remove anything with `gray` or `grey` or `light` in the color name.

```{r}
colors <- grDevices::colors()[grep('gr(a|e)y|light', grDevices::colors(), invert = T)]
```

Then pick enough colors from that list so that each `cca_cluster` has its own color

```{r}
cca_cluster_colors <- sample(x = colors, size = all_data_sub@meta.data$cca_clusters %>% unique() %>% length())
```

Assign names so that each color is associated with a cluster identity:

```{r}
names(cca_cluster_colors) <-all_data_sub@meta.data$cca_clusters %>% unique() 
cca_cluster_colors
```

We can do the same and use the `Zissou` palette with `hcl.colors` (run `hcl.pals()` to see all options)

```{r}
zissou_colors <- hcl.colors( all_data_sub@meta.data$cca_clusters %>% unique() %>% length(), "Zissou 1")
names(zissou_colors) <-all_data_sub@meta.data$cca_clusters %>% unique() 
```

We can also generate new color palettes using RColorBrewer. You can see all of the color palettes available through RColorBrewer if you run `display.brewer.all()`. We specify that we want to use 8 colors from the 'Set2' palette from RColorBrewer, then we use colorRampPalette to expand that palette to make sure we have enough colors for all of the unique clusters.

```{r}
set2_colors <- colorRampPalette(brewer.pal(8, 'Set2'))(all_data_sub@meta.data$cca_clusters %>% unique() %>% length())
```

Then plot the cell using these color themes:
```{r}

DimPlot(
  all_data_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  combine = FALSE, label.size = 2,
  cols = cca_cluster_colors
)
```

```{r}

DimPlot(
  all_data_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  combine = FALSE, label.size = 2,
  cols = set2_colors
)
```


We can leave the legend off, use the Zissou colors, omit the `split_by` argument and the legend:

```{r}
zissou_plot <- DimPlot(
  all_data_sub,
  reduction = "umap.cca",
  group.by = "cca_clusters",
  cols = zissou_colors
) + NoLegend()
```

Then we can label the clusters:

```{r}
LabelClusters(plot = zissou_plot , id = "cca_clusters", box = T, repel = T)
```

Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always re-split the layers in case you would like to re-perform integrative analysis.

```{r}
all_data_sub <- JoinLayers(all_data_sub, assay ='RNA')
```




## Differential Expression Analysis

The bulk of Seuratâs differential expression features can be accessed through the `FindMarkers()` function. By default, Seurat performs differential expression (DE) testing based on the non-parametric Wilcoxon rank sum test. To test for DE genes between two specific groups of cells, specify the `ident.1` and `ident.2` parameters. Since we normalized using SCTransform, we have to run `PrepSCTFindMarkers()` first. Given a merged object with multiple SCT models, this function uses minimum of the median UMI (calculated using the raw UMI counts) of individual objects to reverse the individual SCT regression model using minimum of median UMI as the sequencing depth covariate. The counts slot of the SCT assay is replaced with recorrected counts and the data slot is replaced with log1p of recorrected counts. Then set the `DefaultAssay` to be the RNA assay.

```{r}
Idents(all_data_sub) <- "orig.ident"
all_data_sub <- PrepSCTFindMarkers(all_data_sub)
DefaultAssay(all_data_sub) <- "RNA"

stim_vs_ctrl <- FindMarkers(all_data_sub, ident.1 = "IMMUNE_STIM", ident.2 = "IMMUNE_CTRL")
head(stim_vs_ctrl %>% dplyr::filter(p_val_adj < .05 & avg_log2FC > 1))
```

The results data frame has the following columns :

```         
p_val : p-value (unadjusted)
avg_log2FC : log fold-change of the average expression between the two groups. Positive values indicate that the feature is more highly expressed in the first group.
pct.1 : The percentage of cells where the feature is detected in the first group
pct.2 : The percentage of cells where the feature is detected in the second group
p_val_adj : Adjusted p-value, based on Bonferroni correction using all features in the dataset.
```

If the `ident.2` argument is omitted, `FindMarkers` will test for differentially expressed features between the group specified by `ident.1` and all other cells. Additionally, the parameter `only.pos` can be set to TRUE to only search for positive markers, i.e. features that are more highly expressed in the ident.1 group.

```{r}
stim_vs_all <- FindMarkers(all_data_sub, ident.1 = "IMMUNE_STIM", only.pos = T)
head(stim_vs_all %>% dplyr::filter(p_val_adj < .05 & avg_log2FC > 1))
```

We can switch idents to find marker genes for the clusters:

```{r}
Idents(all_data_sub) <- 'cca_clusters'
```

Use `FindAllMarkers` to compare each cluster to all the other clusters. For the sake of speed, we are selecting only positive genes that are expressed in at least 90% of the cells for a given cluster:

```{r}
cca_markers <- FindAllMarkers(all_data_sub, min.pct = .90, only.pos=TRUE)
```

Look at the marker genes with the biggest fold change per cluster

```{r}
top_cluster_markers <- 
  cca_markers %>% 
  group_by(cluster) %>%
  dplyr::filter(p_val_adj <= 1e-100) %>%
  dplyr::filter(avg_log2FC > 1) %>% 
  dplyr::filter(pct.1 > .9) %>%
  slice_max(n = 2, order_by = abs(avg_log2FC))
top_cluster_markers
```

Make a `FeaturePlot` to look at the expression of one of the cluster markers. It will plot the `data` slot from the default assay. We can switch the default assay to SCT first and specify that we want to use the `data` slot (log1p(counts)):

```{r}
DefaultAssay(all_data_sub) <- "SCT"

FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.cca', order = T, slot = 'data')
```

We can adjust the default colors and use one of the `viridis` palettes:

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.cca', order = T, slot = 'data') & ggplot2::scale_color_gradientn(colors = viridis::turbo(n = 10, direction = 1))

```

We can add the cluster labels:

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = viridis::turbo(n = 10, direction = 1))

```

We can use `RColorBrewer` palettes instead and specify that we want to drop the colors on the extreme ends of the `Spectral` palette:

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8])
```

And add a legend title

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.cca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8]) & ggplot2::labs(color = "log1p\n(counts)")
```

We can also make a heatmap of the cluster markers. Seurat heatmaps use the `scale.data` slot by default.

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene)
```

We can customize this heatmap as well:

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() 
```

We can adjust which legends are shown, like this:

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() & ggplot2::guides(fill=FALSE)
```

Or like this:

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() & ggplot2::guides(colour=FALSE)
```
Another helpful visualization from Seurat is `DotPlot`. The size of each dot indicates the percentage of cells expressing the feature and the color is the average expression level. It uses the scale.data slot by default.

```{r}
DotPlot(all_data_sub, features = top_cluster_markers$gene) 
```

We can use more custom colors:

```{r}
DotPlot(all_data_sub, features = top_cluster_markers$gene) & 
    viridis::scale_color_viridis(option = "magma", direction = -1) 
```
